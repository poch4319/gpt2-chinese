{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import argparse\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from torch.nn import DataParallel\n",
    "from tokenizations.bpe_tokenizer import get_encoder\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 預處理資料集\n",
    "- 把初始句和回答結合成一個文本 (data point)\n",
    "- 只保留回答的情緒 (在 prediction 時該情緒可以用來引導情緒回達)\n",
    "- 載入 tokenizer 然後加入新的情緒 token\n",
    "- 用 tokenizer 把文本轉換成 ids 並存檔\n",
    "- 存檔加入新情緒 token 的 tokenizer\n",
    "- dataset : https://www.biendata.xyz/ccf_tcci2018/datasets/ecg/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "s2t.json Simplified Chinese to Traditional Chinese 簡體到繁體\n",
    "t2s.json Traditional Chinese to Simplified Chinese 繁體到簡體\n",
    "s2tw.json Simplified Chinese to Traditional Chinese (Taiwan Standard) 簡體到臺灣正體\n",
    "tw2s.json Traditional Chinese (Taiwan Standard) to Simplified Chinese 臺灣正體到簡體\n",
    "s2hk.json Simplified Chinese to Traditional Chinese (Hong Kong variant) 簡體到香港繁體\n",
    "hk2s.json Traditional Chinese (Hong Kong variant) to Simplified Chinese 香港繁體到簡體\n",
    "s2twp.json Simplified Chinese to Traditional Chinese (Taiwan Standard) with Taiwanese idiom 簡體到繁體（臺灣正體標準）並轉換爲臺灣常用詞彙\n",
    "tw2sp.json Traditional Chinese (Taiwan Standard) to Simplified Chinese with Mainland Chinese idiom 繁體（臺灣正體標準）到簡體並轉換爲中國大陸常用詞彙\n",
    "t2tw.json Traditional Chinese (OpenCC Standard) to Taiwan Standard 繁體（OpenCC 標準）到臺灣正體\n",
    "hk2t.json Traditional Chinese (Hong Kong variant) to Traditional Chinese 香港繁體到繁體（OpenCC 標準）\n",
    "t2hk.json Traditional Chinese (OpenCC Standard) to Hong Kong variant 繁體（OpenCC 標準）到香港繁體\n",
    "t2jp.json Traditional Chinese Characters (Kyūjitai) to New Japanese Kanji (Shinjitai) 繁體（OpenCC 標準，舊字體）到日文新字體\n",
    "jp2t.json New Japanese Kanji (Shinjitai) to Traditional Chinese Characters (Kyūjitai) 日文新字體到繁體（OpenCC 標準，舊字體）\n",
    "tw2t.json Traditional Chinese (Taiwan standard) to Traditional Chinese 臺灣正體到繁體（OpenCC 標準）\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opencc\n",
    "emotion_dict = {0: '[其他]', \\\n",
    "                1: '[喜歡]', \\\n",
    "                2: '[悲傷]', \\\n",
    "                3: '[噁心]', \\\n",
    "                4: '[憤怒]', \\\n",
    "                5: '[喜樂]'}\n",
    "\n",
    "converter = opencc.OpenCC('s2t.json')\n",
    "\n",
    "\n",
    "\n",
    "import json\n",
    "with open(\"data/ecg_train_data.json\", encoding=\"utf-8\") as f:\n",
    "    lines = json.load(f)\n",
    "    processed = []\n",
    "    for line in lines:\n",
    "        post = converter.convert(line[0][0]).strip() # 起始句轉成繁體, 丟掉情緒標籤\n",
    "        emo = emotion_dict[line[1][1]] #回答句的情緒標籤\n",
    "        reply = converter.convert(line[1][0]).strip() #回答句標籤轉成中文放在句首，並轉成繁體\n",
    "        processed.extend([post + emo + reply])\n",
    "        #print(line)\n",
    "\n",
    "with open(\"data/ecg_train_data_processed.json\", 'w') as fi:\n",
    "    json.dump(processed, fi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/ecg_train_data_processed.json\", encoding=\"utf-8\") as f:\n",
    "    lines = json.load(f)\n",
    "    for line in lines:\n",
    "        print(line)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料轉換成 token ids 並儲存\n",
    "def build_files(data_path, tokenized_data_path, num_pieces, full_tokenizer, min_length):\n",
    "    #num_pieces 将训练语料分成多少份\n",
    "    with open(data_path, 'r', encoding='utf8') as f:\n",
    "        print('reading lines')\n",
    "        lines = json.load(f)\n",
    "        lines = [line.replace('\\n', ' [SEP] ') for line in lines]  # 用[SEP]表示换行, 段落之间使用SEP表示段落结束\n",
    "    all_len = len(lines)\n",
    "    if not os.path.exists(tokenized_data_path):\n",
    "        os.mkdir(tokenized_data_path)\n",
    "    for i in tqdm(range(num_pieces)):\n",
    "        sublines = lines[all_len // num_pieces * i: all_len // num_pieces * (i + 1)]\n",
    "        if i == num_pieces - 1:\n",
    "            sublines.extend(lines[all_len // num_pieces * (i + 1):])  # 把尾部例子添加到最后一个piece\n",
    "        sublines = [full_tokenizer.tokenize(line) for line in sublines if\n",
    "                    len(line) > min_length]  # 只考虑长度超过min_length的句子\n",
    "        sublines = [full_tokenizer.convert_tokens_to_ids(line) for line in sublines]\n",
    "        full_line = []\n",
    "        for subline in sublines:\n",
    "            full_line.append(full_tokenizer.convert_tokens_to_ids('[MASK]'))  # 文章开头添加MASK表示文章开始\n",
    "            full_line.extend(subline)\n",
    "            full_line.append(full_tokenizer.convert_tokens_to_ids('[CLS]'))  # 文章之间添加CLS表示文章结束\n",
    "        with open(tokenized_data_path + 'tokenized_train_{}.txt'.format(i), 'w') as f:\n",
    "            for id in full_line:\n",
    "                f.write(str(id) + ' ')\n",
    "    print('finish')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## add special tokens\n",
    "from tokenizations import tokenization_bert_word_level as tokenization_bert\n",
    "added_tokens = {'additional_special_tokens':['[其他]', '[喜歡]', '[悲傷]', '[噁心]', '[憤怒]', '[喜樂]']}\n",
    "\n",
    "full_tokenizer = tokenization_bert.BertTokenizer(vocab_file='pretrained_model/vocab.txt')  \n",
    "full_tokenizer.max_len = full_tokenizer.add_special_tokens(added_tokens)   #要把 additional_special_tokens 這個 Key 加入 list of your special tokens, 其他例如 cls 他本身就有排好 cls key了\n",
    "\n",
    "\n",
    "#model.resize_token_embeddings(len(full_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test the added speical tokens\n",
    "print(full_tokenizer.additional_special_tokens)\n",
    "print(full_tokenizer.additional_special_tokens_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\johnny.chang\\anaconda3\\envs\\chattwo\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'full_tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# save updated tokenizer\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m torch\u001b[39m.\u001b[39msave(full_tokenizer, \u001b[39m\"\u001b[39m\u001b[39mmanmade/tokenizer.ckpt\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'full_tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# save updated tokenizer\n",
    "\n",
    "import torch\n",
    "torch.save(full_tokenizer, \"manmade/tokenizer.ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[1;32m----> 5\u001b[0m build_files(\u001b[39m\"\u001b[39m\u001b[39mdata/ecg_train_data_processed.json\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdata/\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m100\u001b[39m, full_tokenizer, \u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'build_files' is not defined"
     ]
    }
   ],
   "source": [
    "## build file for training\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "build_files(\"data/ecg_train_data_processed.json\", \"data/\", 100, full_tokenizer, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model\n",
    "- load pretrained model\n",
    "- expand embedding dimensions for added special tokens\n",
    "- forward to training section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded succeed\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "full_tokenizer = torch.load(\"manmade/tokenizer.ckpt\", map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(21134, 768)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "pretrained_model_loc = \"./pretrained_model/\"\n",
    "#model = transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel.from_pretrained(config='./pretrained_model/config.json', \n",
    "#                                                                            pretrained_weights='./pretrained_model/pytorch_model.bin', \n",
    "#                                                                            vocab_file='./pretrained_model/vocab.txt')\n",
    "model = transformers.modeling_gpt2.GPT2LMHeadModel.from_pretrained(\"./pretrained_model/\")\n",
    "model.resize_token_embeddings(len(full_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config:\n",
      "{\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 400\n",
      "    }\n",
      "  },\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "n_ctx: 1024\n"
     ]
    }
   ],
   "source": [
    "model_config = transformers.modeling_gpt2.GPT2Config.from_json_file(\"./pretrained_model/config.json\")\n",
    "print('config:\\n' + model_config.to_json_string())\n",
    "n_ctx = model_config.n_ctx\n",
    "print(f'n_ctx: {n_ctx}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "- 然後 model 的 vocab 記得要先擴充，因為 tokenizer 擴充了 而且辭典也擴充了 \n",
    "- 新的 vocab 應該也要存在某個地方，這樣新 init 的 tokenizer 才能讀取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(21134, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=21128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "num_pieces = 100\n",
    "batch_size = 8\n",
    "stride = 768 #训练时取训练数据的窗口步长\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "multi_gpu = False\n",
    "gradient_accumulation = 1 #'梯度积累'\n",
    "\n",
    "total_steps = int(full_len / stride * epochs / batch_size / gradient_accumulation)\n",
    "lr =1.5e-4\n",
    "warmup_steps = 2000\n",
    "\n",
    "optimizer = transformers.AdamW(model.parameters(), lr=lr, correct_bias=True)\n",
    "scheduler = transformers.WarmupLinearSchedule(optimizer, warmup_steps=warmup_steps,\n",
    "                                                        t_total=total_steps)\n",
    "fp16 = False # 混合精度 # 不支持半精度的显卡请勿打开\n",
    "overall_step = 0\n",
    "#tb_writer = SummaryWriter(log_dir=args.writer_dir)\n",
    "log_step = 1 #'多少步汇报一次loss，设置为gradient accumulation的整数倍'\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "        print('epoch {}'.format(epoch + 1))\n",
    "        now = datetime.now()\n",
    "        print('time: {}'.format(now))\n",
    "        x = np.linspace(0, num_pieces - 1, num_pieces, dtype=np.int32)\n",
    "        random.shuffle(x)\n",
    "        piece_num = 0\n",
    "        for i in x:\n",
    "            with open('data/' + 'tokenized_train_{}.txt'.format(i), 'r') as f:\n",
    "                line = f.read().strip()\n",
    "            tokens = line.split()\n",
    "            tokens = [int(token) for token in tokens]\n",
    "            start_point = 0\n",
    "            samples = []\n",
    "            while start_point < len(tokens) - n_ctx:\n",
    "                samples.append(tokens[start_point: start_point + n_ctx])\n",
    "                start_point += stride\n",
    "            if start_point < len(tokens):\n",
    "                samples.append(tokens[len(tokens)-n_ctx:])\n",
    "            random.shuffle(samples)\n",
    "            for step in range(len(samples) // batch_size):  # drop last\n",
    "\n",
    "                #  prepare data\n",
    "                batch = samples[step * batch_size: (step + 1) * batch_size]\n",
    "                batch_inputs = []\n",
    "                for ids in batch:\n",
    "                    int_ids = [int(x) for x in ids]\n",
    "                    batch_inputs.append(int_ids)\n",
    "                batch_inputs = torch.tensor(batch_inputs).long().to(device)\n",
    "\n",
    "                #  forward pass\n",
    "                outputs = model.forward(input_ids=batch_inputs, labels=batch_inputs)\n",
    "                loss, logits = outputs[:2]\n",
    "\n",
    "                #  get loss\n",
    "                if multi_gpu:\n",
    "                    loss = loss.mean()\n",
    "                if gradient_accumulation > 1:\n",
    "                    loss = loss / gradient_accumulation\n",
    "\n",
    "                #  loss backward\n",
    "                #if fp16:\n",
    "                #    with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                #        scaled_loss.backward()\n",
    "                #        torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), max_grad_norm)\n",
    "                #else:\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "\n",
    "                #  optimizer step\n",
    "                if (overall_step + 1) % gradient_accumulation == 0:\n",
    "                    running_loss += loss.item()\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                    scheduler.step()\n",
    "                if (overall_step + 1) % log_step == 0:\n",
    "                    #tb_writer.add_scalar('loss', loss.item() * gradient_accumulation, overall_step)\n",
    "                    print('now time: {}:{}. Step {} of piece {} of epoch {}, loss {}'.format(\n",
    "                        datetime.now().hour,\n",
    "                        datetime.now().minute,\n",
    "                        step + 1,\n",
    "                        piece_num,\n",
    "                        epoch + 1,\n",
    "                        running_loss * gradient_accumulation / (log_step / gradient_accumulation)))\n",
    "                    running_loss = 0\n",
    "                overall_step += 1\n",
    "            piece_num += 1\n",
    "\n",
    "        print('saving model for epoch {}'.format(epoch + 1))\n",
    "        if not os.path.exists(output_dir + 'model_epoch{}'.format(epoch + 1)):\n",
    "            os.mkdir(output_dir + 'model_epoch{}'.format(epoch + 1))\n",
    "        model_to_save = model.module if hasattr(model, 'module') else model\n",
    "        model_to_save.save_pretrained(output_dir + 'model_epoch{}'.format(epoch + 1))\n",
    "        # torch.save(scheduler.state_dict(), output_dir + 'model_epoch{}/scheduler.pt'.format(epoch + 1))\n",
    "        # torch.save(optimizer.state_dict(), output_dir + 'model_epoch{}/optimizer.pt'.format(epoch + 1))\n",
    "        print('epoch {} finished'.format(epoch + 1))\n",
    "\n",
    "        then = datetime.now()\n",
    "        print('time: {}'.format(then))\n",
    "        print('time for one epoch: {}'.format(then - now))\n",
    "\n",
    "    print('training finished')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chattwo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e64eee62b8c37dc64b8b380d3356b3dc4e38b0e834002de71da9f8165807feaf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
